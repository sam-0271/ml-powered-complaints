{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eefc6047-4307-4130-b422-9045041e298f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "df['filing_date'] = pd.to_datetime(df['filing_date'], dayfirst=False)  # or omit dayfirst as it defaults to False\n",
    "df['resolution_date'] = pd.to_datetime(df['resolution_date'], dayfirst=False)  # or omit dayfirst as it defaults to False\n",
    "\n",
    "# Calculate the resolved_days\n",
    "df['resolved_days'] = (df['resolution_date'] - df['filing_date']).dt.days\n",
    "\n",
    "# Save to a new CSV file\n",
    "df.to_csv('final_complaints.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "249c48d7-0643-4ee6-bdac-fba7311c87cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your CSV file\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Convert 'filing_date' column to string first, then replace 2025 with 2024\n",
    "df['filing_date'] = df['filing_date'].astype(str).str.replace('2025', '2024')\n",
    "\n",
    "# Convert back to datetime if you need the column in date format\n",
    "df['filing_date'] = pd.to_datetime(df['filing_date'], format='%Y-%m-%d')\n",
    "\n",
    "# Save to a new CSV file\n",
    "df.to_csv('final_complaints.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9258886d-3817-48da-8e25-222aa918ae03",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'final_complaints.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m df_filtered \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_cost\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Save the filtered data back to the same CSV file\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[43mdf_filtered\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfinal_complaints.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Display the first few rows of the filtered DataFrame\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_filtered\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'final_complaints.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Filter out rows where 'predicted_cost' is negative\n",
    "df_filtered = df[df['predicted_cost'] >= 0]\n",
    "\n",
    "# Save the filtered data back to the same CSV file\n",
    "df_filtered.to_csv('final_complaints.csv', index=False)\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "print(df_filtered.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6543bb7f-ebee-4f1e-8bb6-e3cbd054a004",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'status_encoded'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'status_encoded'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_complaints.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Check correlation between resolved_days and status (if status is numeric or can be encoded)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m correlation \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresolved_days\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcorr(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstatus_encoded\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)  \u001b[38;5;66;03m# assuming 'status' is encoded as numeric\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCorrelation between resolved_days and status:\u001b[39m\u001b[38;5;124m\"\u001b[39m, correlation)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'status_encoded'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Check correlation between resolved_days and status (if status is numeric or can be encoded)\n",
    "correlation = df['resolved_days'].corr(df['status_encoded'])  # assuming 'status' is encoded as numeric\n",
    "print(\"Correlation between resolved_days and status:\", correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8af94b5e-a103-47bf-b063-2ebf8696d013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between resolved_days and status: 0.031760094689037226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the 'status' column (this will create a numeric representation of 'Completed', 'Pending', 'Escalated')\n",
    "df['status_encoded'] = label_encoder.fit_transform(df['status'])\n",
    "\n",
    "# Now check the correlation between 'resolved_days' and 'status_encoded'\n",
    "correlation = df['resolved_days'].corr(df['status_encoded'])\n",
    "print(\"Correlation between resolved_days and status:\", correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecc4449d-1d8f-4d03-b62d-356886dc2697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between area and status: 0.029745591914071102\n",
      "Correlation between type and status: -0.006153480310181122\n",
      "Correlation between department and status: 0.015637116670047056\n",
      "Correlation between predicted_priority and status: 0.012214815879332519\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the 'status' column into numeric values\n",
    "df['status_encoded'] = label_encoder.fit_transform(df['status'])\n",
    "\n",
    "# Encode other categorical features into numeric values\n",
    "df['area_encoded'] = label_encoder.fit_transform(df['area'])\n",
    "df['type_encoded'] = label_encoder.fit_transform(df['type'])\n",
    "df['department_encoded'] = label_encoder.fit_transform(df['department'])\n",
    "df['predicted_priority_encoded'] = label_encoder.fit_transform(df['predicted_priority'])\n",
    "\n",
    "# Now compute the correlation between the encoded features and the target 'status_encoded'\n",
    "correlation_area = df['area_encoded'].corr(df['status_encoded'])\n",
    "correlation_type = df['type_encoded'].corr(df['status_encoded'])\n",
    "correlation_department = df['department_encoded'].corr(df['status_encoded'])\n",
    "correlation_predicted_priority = df['predicted_priority_encoded'].corr(df['status_encoded'])\n",
    "\n",
    "# Print the correlations\n",
    "print(f\"Correlation between area and status: {correlation_area}\")\n",
    "print(f\"Correlation between type and status: {correlation_type}\")\n",
    "print(f\"Correlation between department and status: {correlation_department}\")\n",
    "print(f\"Correlation between predicted_priority and status: {correlation_predicted_priority}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "204ff2c4-3ed8-471b-834e-3cd894d7dd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filing_date resolution_date_new  resolved_days_new\n",
      "0  2024-01-13          2024-01-20                  7\n",
      "1  2024-02-28          2024-03-19                 20\n",
      "2  2024-02-03          2024-03-03                 29\n",
      "3  2024-04-09          2024-04-24                 15\n",
      "4  2024-01-20          2024-01-31                 11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Convert the 'filing_date' column to datetime if it's not already\n",
    "df['filing_date'] = pd.to_datetime(df['filing_date'])\n",
    "\n",
    "# Generate a random number of days for resolution (for example, between 1 and 30 days)\n",
    "np.random.seed(42)  # for reproducibility\n",
    "df['random_days_for_resolution'] = np.random.randint(1, 31, size=len(df))\n",
    "\n",
    "# Calculate the 'resolution_date_new' by adding the random days to the filing date\n",
    "df['resolution_date_new'] = df['filing_date'] + pd.to_timedelta(df['random_days_for_resolution'], unit='D')\n",
    "\n",
    "# Calculate the 'resolved_days_new' by finding the difference between 'filing_date' and 'resolution_date_new'\n",
    "df['resolved_days_new'] = (df['resolution_date_new'] - df['filing_date']).dt.days\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[['filing_date', 'resolution_date_new', 'resolved_days_new']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc4e3f71-e3d8-4767-8a5d-dc753e2c8093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filing_date           area               type         department  \\\n",
      "0  2024-01-13        Bavdhan      Garbage Issue      Garbage Issue   \n",
      "1  2024-02-28       Hadapsar  Electricity Issue        Road Damage   \n",
      "2  2024-02-03  Koregaon Park    Illegal Parking        Road Damage   \n",
      "3  2024-04-09      Bibwewadi      Garbage Issue  Electricity Issue   \n",
      "4  2024-01-20   Shivajinagar       Tree Falling       Tree Falling   \n",
      "\n",
      "  predicted_priority       status  resolved_days_new  resolution_date_new  \n",
      "0             Medium  In Progress               18.0  1706659200000000000  \n",
      "1                Low      Pending                NaN                  NaT  \n",
      "2             Medium     Resolved               15.0  1708214400000000000  \n",
      "3             Medium      Pending                NaN                  NaT  \n",
      "4                Low      Pending                NaN                  NaT  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Step 2: Define a function to assign resolution days based on correlations\n",
    "def assign_resolution_days(row):\n",
    "    # If status is Pending, no resolution date and resolved days\n",
    "    if row['status'] == 'Pending':\n",
    "        return np.nan  # No resolved days for pending complaints\n",
    "    elif row['predicted_priority'] == 'High':\n",
    "        return np.random.randint(1, 10)  # 1 to 10 days for high priority\n",
    "    elif row['predicted_priority'] == 'Medium':\n",
    "        return np.random.randint(10, 20)  # 10 to 20 days for medium priority\n",
    "    else:  # Low priority\n",
    "        return np.random.randint(20, 30)  # 20 to 30 days for low priority\n",
    "\n",
    "# Step 3: Apply the function to assign 'resolved_days_new' for each row\n",
    "df['resolved_days_new'] = df.apply(assign_resolution_days, axis=1)\n",
    "\n",
    "# Step 4: Calculate 'resolution_date_new' by adding 'resolved_days_new' to 'filing_date'\n",
    "df['filing_date'] = pd.to_datetime(df['filing_date'])  # Ensure 'filing_date' is in datetime format\n",
    "\n",
    "# Set resolution date only if 'resolved_days_new' is not NaN (i.e., not Pending)\n",
    "df['resolution_date_new'] = np.where(\n",
    "    df['resolved_days_new'].isna(),\n",
    "    pd.NaT,  # Not a Time if Pending\n",
    "    df['filing_date'] + pd.to_timedelta(df['resolved_days_new'], unit='D')\n",
    ")\n",
    "\n",
    "# Step 5: Save the updated DataFrame back to CSV\n",
    "df.to_csv('final_complaints_updated.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[['filing_date', 'area', 'type', 'department', 'predicted_priority', 'status', 'resolved_days_new', 'resolution_date_new']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e2023e3-0374-4eab-8e5a-0b5f1231591a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filing_date           area               type         department  \\\n",
      "0  2024-01-13        Bavdhan      Garbage Issue      Garbage Issue   \n",
      "1  2024-02-28       Hadapsar  Electricity Issue        Road Damage   \n",
      "2  2024-02-03  Koregaon Park    Illegal Parking        Road Damage   \n",
      "3  2024-04-09      Bibwewadi      Garbage Issue  Electricity Issue   \n",
      "4  2024-01-20   Shivajinagar       Tree Falling       Tree Falling   \n",
      "\n",
      "  predicted_priority       status  resolved_days_new resolution_date_new  \n",
      "0             Medium  In Progress               12.0          2024-01-25  \n",
      "1                Low      Pending                NaN                 NaT  \n",
      "2             Medium     Resolved               10.0          2024-02-13  \n",
      "3             Medium      Pending                NaN                 NaT  \n",
      "4                Low      Pending                NaN                 NaT  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Step 2: Define a function to assign resolution days based on correlations\n",
    "def assign_resolution_days(row):\n",
    "    # If status is Pending, no resolution date and resolved days\n",
    "    if row['status'] == 'Pending':\n",
    "        return np.nan  # No resolved days for pending complaints\n",
    "    elif row['predicted_priority'] == 'High':\n",
    "        return np.random.randint(1, 10)  # 1 to 10 days for high priority\n",
    "    elif row['predicted_priority'] == 'Medium':\n",
    "        return np.random.randint(10, 20)  # 10 to 20 days for medium priority\n",
    "    else:  # Low priority\n",
    "        return np.random.randint(20, 30)  # 20 to 30 days for low priority\n",
    "\n",
    "# Step 3: Apply the function to assign 'resolved_days_new' for each row\n",
    "df['resolved_days_new'] = df.apply(assign_resolution_days, axis=1)\n",
    "\n",
    "# Step 4: Calculate 'resolution_date_new' by adding 'resolved_days_new' to 'filing_date'\n",
    "df['filing_date'] = pd.to_datetime(df['filing_date'])  # Ensure 'filing_date' is in datetime format\n",
    "\n",
    "# Set resolution date only if 'resolved_days_new' is not NaN (i.e., not Pending)\n",
    "df['resolution_date_new'] = np.where(\n",
    "    df['resolved_days_new'].isna(),\n",
    "    pd.NaT,  # Not a Time if Pending\n",
    "    df['filing_date'] + pd.to_timedelta(df['resolved_days_new'], unit='D')\n",
    ")\n",
    "\n",
    "# Convert resolution_date_new to datetime format explicitly\n",
    "df['resolution_date_new'] = pd.to_datetime(df['resolution_date_new'], errors='coerce')\n",
    "\n",
    "# Step 5: Save the updated DataFrame back to CSV\n",
    "df.to_csv('final_complaints_updated.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[['filing_date', 'area', 'type', 'department', 'predicted_priority', 'status', 'resolved_days_new', 'resolution_date_new']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "958eeefb-c114-4e7c-b476-76a5823dc4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between resolved_days_new and status: nan\n",
      "Correlation between resolution_date_new and status: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMYAK KHANDERAO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('final_complaints_updated.csv')\n",
    "\n",
    "# Step 2: Convert 'status' to numerical values\n",
    "status_mapping = {\n",
    "    'Pending': 0,\n",
    "    'Completed': 1,\n",
    "    'Escalated': 2  # Add more if you have other status categories\n",
    "}\n",
    "df['status_numerical'] = df['status'].map(status_mapping)\n",
    "\n",
    "# Step 3: Handle missing values in resolved_days_new and resolution_date_new\n",
    "df['resolved_days_new'] = df['resolved_days_new'].fillna(np.nan)\n",
    "df['resolution_date_new'] = pd.to_datetime(df['resolution_date_new'], errors='coerce')\n",
    "\n",
    "# Step 4: Calculate the correlation between resolved_days_new, resolution_date_new, and status\n",
    "correlation_resolved_days = df['resolved_days_new'].corr(df['status_numerical'])\n",
    "correlation_resolution_date = df['resolution_date_new'].apply(lambda x: x.timestamp() if pd.notna(x) else np.nan).corr(df['status_numerical'])\n",
    "\n",
    "# Step 5: Print the correlation results\n",
    "print(f\"Correlation between resolved_days_new and status: {correlation_resolved_days}\")\n",
    "print(f\"Correlation between resolution_date_new and status: {correlation_resolution_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1ff96cc-6fdc-482c-964c-043b043fbb68",
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.StrDType'> could not be promoted by <class 'numpy.dtypes.DateTime64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.DateTime64DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiling_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiling_date\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Ensure 'filing_date' is in datetime format\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Set resolution date only if 'resolved_days_new' is not 0 (i.e., not Pending)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresolution_date_new\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstatus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPending\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set resolution_date_new to '0' if Pending\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiling_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_timedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresolved_days_new\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Ensure that 'resolved_days_new' is 0 if the status is Pending\u001b[39;00m\n\u001b[0;32m     33\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresolved_days_new\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m     34\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPending\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# Set resolved_days_new to 0 if Pending\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresolved_days_new\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Keep the original resolved_days_new if not Pending\u001b[39;00m\n\u001b[0;32m     37\u001b[0m )\n",
      "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.StrDType'> could not be promoted by <class 'numpy.dtypes.DateTime64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.DateTime64DType'>)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('final_complaints_updated.csv')\n",
    "\n",
    "# Step 2: Define a function to assign resolution days based on correlations\n",
    "def assign_resolution_days(row):\n",
    "    # If status is Pending, set resolved days to 0\n",
    "    if row['status'] == 'Pending':\n",
    "        return 0  # Set resolved_days_new to 0 for pending complaints\n",
    "    elif row['predicted_priority'] == 'High':\n",
    "        return np.random.randint(1, 10)  # 1 to 10 days for high priority\n",
    "    elif row['predicted_priority'] == 'Medium':\n",
    "        return np.random.randint(10, 20)  # 10 to 20 days for medium priority\n",
    "    else:  # Low priority\n",
    "        return np.random.randint(20, 30)  # 20 to 30 days for low priority\n",
    "\n",
    "# Step 3: Apply the function to assign 'resolved_days_new' for each row\n",
    "df['resolved_days_new'] = df.apply(assign_resolution_days, axis=1)\n",
    "\n",
    "# Step 4: Calculate 'resolution_date_new' by adding 'resolved_days_new' to 'filing_date'\n",
    "df['filing_date'] = pd.to_datetime(df['filing_date'])  # Ensure 'filing_date' is in datetime format\n",
    "\n",
    "# Set resolution date only if 'resolved_days_new' is not 0 (i.e., not Pending)\n",
    "df['resolution_date_new'] = np.where(\n",
    "    df['status'] == 'Pending',\n",
    "    '0',  # Set resolution_date_new to '0' if Pending\n",
    "    df['filing_date'] + pd.to_timedelta(df['resolved_days_new'], unit='D')\n",
    ")\n",
    "\n",
    "# Ensure that 'resolved_days_new' is 0 if the status is Pending\n",
    "df['resolved_days_new'] = np.where(\n",
    "    df['status'] == 'Pending',\n",
    "    0,  # Set resolved_days_new to 0 if Pending\n",
    "    df['resolved_days_new']  # Keep the original resolved_days_new if not Pending\n",
    ")\n",
    "\n",
    "# Step 5: Save the updated DataFrame back to CSV\n",
    "df.to_csv('final_complaints_updated.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[['filing_date', 'area', 'type', 'department', 'predicted_priority', 'status', 'resolved_days_new', 'resolution_date_new']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21255629-45c5-4643-8c74-62731529c8f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.StrDType'> could not be promoted by <class 'numpy.dtypes.DateTime64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.DateTime64DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiling_date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiling_date\u001b[39m\u001b[38;5;124m'\u001b[39m])  \u001b[38;5;66;03m# Ensure 'filing_date' is in datetime format\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Set resolution date only if 'resolved_days_new' is not 0 (i.e., not Pending)\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresolution_date_new\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstatus\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPending\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set resolution_date_new to '0' if Pending\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiling_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_timedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresolved_days_new\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Ensure that 'resolved_days_new' is 0 if the status is Pending\u001b[39;00m\n\u001b[0;32m     33\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresolved_days_new\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(\n\u001b[0;32m     34\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPending\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# Set resolved_days_new to 0 if Pending\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresolved_days_new\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Keep the original resolved_days_new if not Pending\u001b[39;00m\n\u001b[0;32m     37\u001b[0m )\n",
      "\u001b[1;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.StrDType'> could not be promoted by <class 'numpy.dtypes.DateTime64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.StrDType'>, <class 'numpy.dtypes.DateTime64DType'>)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('final_complaints_updated.csv')\n",
    "\n",
    "# Step 2: Define a function to assign resolution days based on correlations\n",
    "def assign_resolution_days(row):\n",
    "    # If status is Pending, set resolved days to 0\n",
    "    if row['status'] == 'Pending':\n",
    "        return 0  # Set resolved_days_new to 0 for pending complaints\n",
    "    elif row['predicted_priority'] == 'High':\n",
    "        return np.random.randint(1, 10)  # 1 to 10 days for high priority\n",
    "    elif row['predicted_priority'] == 'Medium':\n",
    "        return np.random.randint(10, 20)  # 10 to 20 days for medium priority\n",
    "    else:  # Low priority\n",
    "        return np.random.randint(20, 30)  # 20 to 30 days for low priority\n",
    "\n",
    "# Step 3: Apply the function to assign 'resolved_days_new' for each row\n",
    "df['resolved_days_new'] = df.apply(assign_resolution_days, axis=1)\n",
    "\n",
    "# Step 4: Calculate 'resolution_date_new' by adding 'resolved_days_new' to 'filing_date'\n",
    "df['filing_date'] = pd.to_datetime(df['filing_date'])  # Ensure 'filing_date' is in datetime format\n",
    "\n",
    "# Set resolution date only if 'resolved_days_new' is not 0 (i.e., not Pending)\n",
    "df['resolution_date_new'] = np.where(\n",
    "    df['status'] == 'Pending',\n",
    "    '0',  # Set resolution_date_new to '0' if Pending\n",
    "    df['filing_date'] + pd.to_timedelta(df['resolved_days_new'], unit='D')\n",
    ")\n",
    "\n",
    "# Ensure that 'resolved_days_new' is 0 if the status is Pending\n",
    "df['resolved_days_new'] = np.where(\n",
    "    df['status'] == 'Pending',\n",
    "    0,  # Set resolved_days_new to 0 if Pending\n",
    "    df['resolved_days_new']  # Keep the original resolved_days_new if not Pending\n",
    ")\n",
    "\n",
    "# Step 5: Save the updated DataFrame back to CSV\n",
    "df.to_csv('final_complaints_updated.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[['filing_date', 'area', 'type', 'department', 'predicted_priority', 'status', 'resolved_days_new', 'resolution_date_new']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8b52ec3-6a58-49e0-b68a-d3eee3ebde1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  filing_date           area               type         department  \\\n",
      "0  2024-01-13        Bavdhan      Garbage Issue      Garbage Issue   \n",
      "1  2024-02-28       Hadapsar  Electricity Issue        Road Damage   \n",
      "2  2024-02-03  Koregaon Park    Illegal Parking        Road Damage   \n",
      "3  2024-04-09      Bibwewadi      Garbage Issue  Electricity Issue   \n",
      "4  2024-01-20   Shivajinagar       Tree Falling       Tree Falling   \n",
      "\n",
      "  predicted_priority       status  resolved_days_new  resolution_date_new  \n",
      "0             Medium  In Progress                 16  1706486400000000000  \n",
      "1                Low      Pending                  0                  NaT  \n",
      "2             Medium     Resolved                 14  1708128000000000000  \n",
      "3             Medium      Pending                  0                  NaT  \n",
      "4                Low      Pending                  0                  NaT  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('final_complaints_updated.csv')\n",
    "\n",
    "# Step 2: Define a function to assign resolution days based on correlations\n",
    "def assign_resolution_days(row):\n",
    "    # If status is Pending, set resolved days to 0\n",
    "    if row['status'] == 'Pending':\n",
    "        return 0  # Set resolved_days_new to 0 for pending complaints\n",
    "    elif row['predicted_priority'] == 'High':\n",
    "        return np.random.randint(1, 10)  # 1 to 10 days for high priority\n",
    "    elif row['predicted_priority'] == 'Medium':\n",
    "        return np.random.randint(10, 20)  # 10 to 20 days for medium priority\n",
    "    else:  # Low priority\n",
    "        return np.random.randint(20, 30)  # 20 to 30 days for low priority\n",
    "\n",
    "# Step 3: Apply the function to assign 'resolved_days_new' for each row\n",
    "df['resolved_days_new'] = df.apply(assign_resolution_days, axis=1)\n",
    "\n",
    "# Step 4: Calculate 'resolution_date_new' by adding 'resolved_days_new' to 'filing_date'\n",
    "df['filing_date'] = pd.to_datetime(df['filing_date'])  # Ensure 'filing_date' is in datetime format\n",
    "\n",
    "# Set resolution date only if 'resolved_days_new' is not 0 (i.e., not Pending)\n",
    "df['resolution_date_new'] = np.where(\n",
    "    df['status'] == 'Pending',\n",
    "    pd.NaT,  # Set resolution_date_new to NaT if Pending\n",
    "    df['filing_date'] + pd.to_timedelta(df['resolved_days_new'], unit='D')\n",
    ")\n",
    "\n",
    "# Ensure that 'resolved_days_new' is 0 if the status is Pending\n",
    "df['resolved_days_new'] = np.where(\n",
    "    df['status'] == 'Pending',\n",
    "    0,  # Set resolved_days_new to 0 if Pending\n",
    "    df['resolved_days_new']  # Keep the original resolved_days_new if not Pending\n",
    ")\n",
    "\n",
    "# Step 5: Save the updated DataFrame back to CSV\n",
    "df.to_csv('final_complaints_updated.csv', index=False)\n",
    "\n",
    "# Display the first few rows to verify\n",
    "print(df[['filing_date', 'area', 'type', 'department', 'predicted_priority', 'status', 'resolved_days_new', 'resolution_date_new']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f406f73d-de3d-47f1-a6a7-f7b07f681ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between status and resolved_days_new: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SAMYAK KHANDERAO\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3045: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_csv('final_complaints_updated.csv')\n",
    "\n",
    "# Step 2: Convert 'status' column to numerical values\n",
    "status_mapping = {'Pending': 0, 'Completed': 1, 'Escalated': 2}\n",
    "df['status_numeric'] = df['status'].map(status_mapping)\n",
    "\n",
    "# Step 3: Calculate the correlation between 'status_numeric' and 'resolved_days_new'\n",
    "correlation = df['status_numeric'].corr(df['resolved_days_new'])\n",
    "\n",
    "# Step 4: Display the correlation result\n",
    "print(f\"Correlation between status and resolved_days_new: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5aa18ddb-89f3-4424-ba9f-2aef386fda64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\SAMYAK\n",
      "[nltk_data]     KHANDERAO\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              rating  feedback_sentiment  \\\n",
      "rating                      1.000000            0.511753   \n",
      "feedback_sentiment          0.511753            1.000000   \n",
      "resolution_status_encoded   0.006766            0.013050   \n",
      "resolved_days               0.002879           -0.004834   \n",
      "predicted_priority_encoded  0.008732           -0.010384   \n",
      "actual_cost                -0.010129           -0.024695   \n",
      "\n",
      "                            resolution_status_encoded  resolved_days  \\\n",
      "rating                                       0.006766       0.002879   \n",
      "feedback_sentiment                           0.013050      -0.004834   \n",
      "resolution_status_encoded                    1.000000       0.017783   \n",
      "resolved_days                                0.017783       1.000000   \n",
      "predicted_priority_encoded                  -0.019912       0.008736   \n",
      "actual_cost                                 -0.679680      -0.017881   \n",
      "\n",
      "                            predicted_priority_encoded  actual_cost  \n",
      "rating                                        0.008732    -0.010129  \n",
      "feedback_sentiment                           -0.010384    -0.024695  \n",
      "resolution_status_encoded                    -0.019912    -0.679680  \n",
      "resolved_days                                 0.008736    -0.017881  \n",
      "predicted_priority_encoded                    1.000000     0.021715  \n",
      "actual_cost                                   0.021715     1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame with 'rating', 'feedback_text', and other necessary columns\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Step 1: Install NLTK and download VADER lexicon (do this once)\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Step 2: Sentiment Analysis on Feedback Text\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "df['feedback_sentiment'] = df['feedback_text'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# Step 3: Encode categorical features (e.g., resolution_status, predicted_priority)\n",
    "le = LabelEncoder()\n",
    "df['resolution_status_encoded'] = le.fit_transform(df['resolution_status'])\n",
    "df['predicted_priority_encoded'] = le.fit_transform(df['predicted_priority'])\n",
    "\n",
    "# Step 4: Calculate correlations\n",
    "correlation_matrix = df[['rating', 'feedback_sentiment', 'resolution_status_encoded', \n",
    "                         'resolved_days', 'predicted_priority_encoded', 'actual_cost']].corr()\n",
    "\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bfcdd4-50e1-4877-91fc-7cb5b3fd55bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
