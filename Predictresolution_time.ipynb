{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4abe567-9aed-4acd-ae63-6ee7faf35557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.51\n",
      "\n",
      "Showing first 10 predictions:\n",
      "\n",
      "Predicted Resolution Time for row 1: 15.91 days\n",
      "Expected Completion Date for row 1: 28 January 2024\n",
      "\n",
      "Predicted Resolution Time for row 2: 0.00 days\n",
      "Expected Completion Date for row 2: 28 February 2024\n",
      "\n",
      "Predicted Resolution Time for row 3: 14.32 days\n",
      "Expected Completion Date for row 3: 17 February 2024\n",
      "\n",
      "Predicted Resolution Time for row 4: 0.00 days\n",
      "Expected Completion Date for row 4: 09 April 2024\n",
      "\n",
      "Predicted Resolution Time for row 5: 0.00 days\n",
      "Expected Completion Date for row 5: 20 January 2024\n",
      "\n",
      "Predicted Resolution Time for row 6: 0.00 days\n",
      "Expected Completion Date for row 6: 28 March 2024\n",
      "\n",
      "Predicted Resolution Time for row 7: 0.00 days\n",
      "Expected Completion Date for row 7: 12 February 2024\n",
      "\n",
      "Predicted Resolution Time for row 8: 23.35 days\n",
      "Expected Completion Date for row 8: 29 April 2024\n",
      "\n",
      "Predicted Resolution Time for row 9: 14.58 days\n",
      "Expected Completion Date for row 9: 17 January 2024\n",
      "\n",
      "Predicted Resolution Time for row 10: 0.00 days\n",
      "Expected Completion Date for row 10: 16 January 2024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('final_complaints.csv')\n",
    "\n",
    "# Convert 'filing_date' to datetime\n",
    "df['filing_date'] = pd.to_datetime(df['filing_date'])\n",
    "\n",
    "# Extract features from 'filing_date'\n",
    "df['filing_year'] = df['filing_date'].dt.year\n",
    "df['filing_month'] = df['filing_date'].dt.month\n",
    "df['filing_day'] = df['filing_date'].dt.day\n",
    "\n",
    "# Save the original filing date before dropping it\n",
    "original_filing_dates = df['filing_date'].copy()\n",
    "\n",
    "# Drop 'filing_date'\n",
    "df.drop('filing_date', axis=1, inplace=True)\n",
    "\n",
    "# One-hot encoding for categorical variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Features and target\n",
    "X = df.drop('resolved_days_new', axis=1)\n",
    "y = df['resolved_days_new']\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling (optional for Random Forest)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create and train the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(model, 'resolution_time_predictor.pkl')\n",
    "\n",
    "# ========== Predict on Full Dataset ==========\n",
    "\n",
    "# Reload original dataset\n",
    "new_data_df = pd.read_csv('final_complaints.csv')\n",
    "new_data_df['filing_date'] = pd.to_datetime(new_data_df['filing_date'])\n",
    "\n",
    "# Save filing_date for later use\n",
    "original_filing_dates = new_data_df['filing_date'].copy()\n",
    "\n",
    "# Extract features from filing_date\n",
    "new_data_df['filing_year'] = new_data_df['filing_date'].dt.year\n",
    "new_data_df['filing_month'] = new_data_df['filing_date'].dt.month\n",
    "new_data_df['filing_day'] = new_data_df['filing_date'].dt.day\n",
    "\n",
    "# Drop 'filing_date' for prediction\n",
    "new_data_df.drop('filing_date', axis=1, inplace=True)\n",
    "\n",
    "# One-hot encoding\n",
    "new_data_df = pd.get_dummies(new_data_df, drop_first=True)\n",
    "\n",
    "# Ensure the new data has the same columns as training data\n",
    "new_data_df = new_data_df.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# Standardize new data\n",
    "new_data_scaled = scaler.transform(new_data_df)\n",
    "\n",
    "# Make predictions\n",
    "predicted_resolution_times = model.predict(new_data_scaled)\n",
    "\n",
    "# ========== Display Results ==========\n",
    "\n",
    "# Show first few predictions\n",
    "num_display = 10\n",
    "print(f\"\\nShowing first {num_display} predictions:\\n\")\n",
    "for i in range(num_display):\n",
    "    filing_date = original_filing_dates.iloc[i]\n",
    "    expected_completion_date = filing_date + pd.to_timedelta(predicted_resolution_times[i], unit='D')\n",
    "    print(f\"Predicted Resolution Time for row {i+1}: {predicted_resolution_times[i]:.2f} days\")\n",
    "    print(f\"Expected Completion Date for row {i+1}: {expected_completion_date.strftime('%d %B %Y')}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ef2208d-cee8-43da-981f-578d2878f1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Showing first 10 predictions:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Predictions: 100%|████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 6365.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Resolution Time for row 1: 15.91 days\n",
      "Expected Completion Date for row 1: 28 January 2024\n",
      "\n",
      "Predicted Resolution Time for row 2: 0.00 days\n",
      "Expected Completion Date for row 2: 28 February 2024\n",
      "\n",
      "Predicted Resolution Time for row 3: 14.32 days\n",
      "Expected Completion Date for row 3: 17 February 2024\n",
      "\n",
      "Predicted Resolution Time for row 4: 0.00 days\n",
      "Expected Completion Date for row 4: 09 April 2024\n",
      "\n",
      "Predicted Resolution Time for row 5: 0.00 days\n",
      "Expected Completion Date for row 5: 20 January 2024\n",
      "\n",
      "Predicted Resolution Time for row 6: 0.00 days\n",
      "Expected Completion Date for row 6: 28 March 2024\n",
      "\n",
      "Predicted Resolution Time for row 7: 0.00 days\n",
      "Expected Completion Date for row 7: 12 February 2024\n",
      "\n",
      "Predicted Resolution Time for row 8: 23.35 days\n",
      "Expected Completion Date for row 8: 29 April 2024\n",
      "\n",
      "Predicted Resolution Time for row 9: 14.58 days\n",
      "Expected Completion Date for row 9: 17 January 2024\n",
      "\n",
      "Predicted Resolution Time for row 10: 0.00 days\n",
      "Expected Completion Date for row 10: 16 January 2024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# ========== Display Results with Progress Bar ==========\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_display = 10\n",
    "print(f\"\\nShowing first {num_display} predictions:\\n\")\n",
    "\n",
    "for i in tqdm(range(num_display), desc=\"Generating Predictions\"):\n",
    "    filing_date = original_filing_dates.iloc[i]\n",
    "    expected_completion_date = filing_date + pd.to_timedelta(predicted_resolution_times[i], unit='D')\n",
    "    print(f\"Predicted Resolution Time for row {i+1}: {predicted_resolution_times[i]:.2f} days\")\n",
    "    print(f\"Expected Completion Date for row {i+1}: {expected_completion_date.strftime('%d %B %Y')}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b52976-ff4e-40f6-857d-8cf33215932e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_columns.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'resolution_time_predictor.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(list(X.columns), 'x_columns.pkl')  # Save column order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e2e9c4d-fe87-40a1-89ac-25d4ccac35dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_columns.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "joblib.dump(list(X.columns), \"x_columns.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c48ed55-6165-4577-834d-7a5ade63929e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x_columns.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model, 'resolution_time_predictor.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "joblib.dump(list(X.columns), 'x_columns.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe4e3313-cbd7-4f37-8a55-15addf01b142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['department_classifier.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "# Sample data\n",
    "departments = [\n",
    "    \"Municipal Waste Management Department\",\n",
    "    \"Electricity Distribution Department\",\n",
    "    \"Traffic and Transportation Department\",\n",
    "    \"Urban Forestry and Landscaping Department\",\n",
    "    \"Public Works Department\",\n",
    "    \"Animal Control and Welfare Department\",\n",
    "    \"Urban Lighting and Infrastructure Department\",\n",
    "    \"Environmental Protection Department\",\n",
    "    \"Water Supply and Sanitation Department\",\n",
    "    \"Sewerage and Drainage Department\"\n",
    "]\n",
    "\n",
    "# Create and fit label encoder\n",
    "dept_label_encoder = LabelEncoder()\n",
    "dept_label_encoder.fit(departments)\n",
    "\n",
    "# Save the encoder\n",
    "joblib.dump(dept_label_encoder, 'department_classifier.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1ea593-9ab5-4aed-af88-6280de45aa10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['priority_predictor.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "priority_label_encoder = LabelEncoder()\n",
    "priority_label_encoder.fit(['Low', 'Medium', 'High'])\n",
    "joblib.dump(priority_label_encoder, 'priority_predictor.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f54c73-bdde-42dc-b880-aea9e50c9606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a250b992-57db-445f-878a-f4a3082b10f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2917f7c4-2b40-4c03-93d5-77626e9fa6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
